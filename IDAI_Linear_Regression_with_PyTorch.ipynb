{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IDAI_Linear_Regression_with_PyTorch",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPHpBsqfaqBRNqu8LLNjE9i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimsooyoung/iap_hanyang/blob/main/IDAI_Linear_Regression_with_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kpJ_RBA5Z8bS"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "º 랜덤한 값을 가지는 텐서 생성\n",
        "\n",
        "1. `torch.rand()` : 0과 1 사이의 숫자를 균등하게 생성\n",
        "2. `torch.rand_like()` : 사이즈를 튜플로 입력하지 않고 기존의 텐서로 정의\n",
        "3. `torch.randn()` : 평균이 0이고 표준편차가 1인 가우시안 정규분포를 이용해 생성\n",
        "4. `torch.randn_like()` :  사이즈를 튜플로 입력하지 않고 기존의 텐서로 정의\n",
        "5. `torch.randint()` : 주어진 범위 내의 정수를 균등하게 생성, 자료형은 torch.float32\n",
        "6. `torch.randint_like()` : 사이즈를 튜플로 입력하지 않고 기존의 텐서로 정의\n",
        "7. `torch.randperm()` : 주어진 범위 내의 정수를 랜덤하게 생성"
      ],
      "metadata": {
        "id": "GgfOoYpwapyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.empty(5, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGBHG23-aOjr",
        "outputId": "33b86729-a56c-4718-d31b-4b7a92f44f31"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[8.2319e-36, 0.0000e+00, 2.3694e-38],\n",
              "        [9.2196e-41, 0.0000e+00, 0.0000e+00],\n",
              "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
              "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
              "        [0.0000e+00, 0.0000e+00, 0.0000e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.rand(5, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgeGKt4gaUpU",
        "outputId": "4ee558ea-1f2a-42f2-b046-015a6a0cce01"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8774, 0.3740, 0.4055],\n",
              "        [0.7391, 0.9450, 0.2407],\n",
              "        [0.4003, 0.7967, 0.4453],\n",
              "        [0.6464, 0.2645, 0.1754],\n",
              "        [0.2309, 0.6678, 0.4656]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.randn(5, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eJ811CAaZ2C",
        "outputId": "15e3effb-f45a-46d7-f11f-43465952b632"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1132, -0.4833,  0.0719],\n",
              "        [ 0.5638, -0.2346,  0.6653],\n",
              "        [-1.7273,  1.9043, -1.0549],\n",
              "        [-0.8937, -0.7524,  2.1464],\n",
              "        [-0.5911, -1.7775,  0.9386]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(1)\n",
        "print(x, x.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8F18yrmnadYO",
        "outputId": "2d511283-747c-4b5a-9bb4-d1f5c7e9e65a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.2883]) 0.288310170173645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "a = torch.ones(5)\n",
        "b = a.numpy()\n",
        "c = np.ones(5)\n",
        "d = torch.from_numpy(c)\n",
        "\n",
        "print(b) # tensor\n",
        "print(a) # numpy\n",
        "print(c) # numpy\n",
        "print(d) # tensor "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbAThAP0a8_8",
        "outputId": "fb112e59-5ca4-4867-b176-81874cd740d2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 1. 1. 1. 1.]\n",
            "tensor([1., 1., 1., 1., 1.])\n",
            "[1. 1. 1. 1. 1.]\n",
            "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using GPU"
      ],
      "metadata": {
        "id": "1mehrnwwbUmu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor((5, 3))\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "y = torch.ones_like(x, device=device)\n",
        "x = x.to(device)\n",
        "z = x + y\n",
        "\n",
        "print(z, z.to('cpu'), torch.double)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8-BmjyqbXHp",
        "outputId": "8359c708-7bf8-4de3-ae4f-01cc5149f6f2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([6, 4], device='cuda:0') tensor([6, 4]) torch.float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cost Function - MSE\n",
        "\n",
        "<img width=\"300\" alt=\"image\" src=\"https://user-images.githubusercontent.com/12381733/167244192-5974984d-a3eb-4682-833f-a4f9c6d41670.png\">\n",
        "\n",
        "```\n",
        "torch.nn.MSELoss(size_average=None, reduce=None, reduction='mean')\n",
        "\n",
        "import torch.nn as nn.criterion = nn.CrossEntropyLoss()\n",
        "...\n",
        "loss = criterion(input, target)\n",
        "```\n",
        "\n",
        "<img width=\"379\" alt=\"image\" src=\"https://user-images.githubusercontent.com/12381733/167244134-18d4ba34-ebd0-4a27-8058-34b684cabad2.png\">\n",
        "\n",
        "```\n",
        "import torch\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)\n",
        "```"
      ],
      "metadata": {
        "id": "1vNI9TFzcbiM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example: Linear Regression \n",
        "\n",
        "<img width=\"335\" alt=\"image\" src=\"https://user-images.githubusercontent.com/12381733/167244269-87d178ab-90bd-4543-9164-df09c656ae39.png\">"
      ],
      "metadata": {
        "id": "ltNFNSb8dPna"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[5], [6], [7]])\n",
        "\n",
        "\n",
        "W = torch.zeros(1, requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "\n",
        "optimizer = optim.SGD([W, b], lr = 0.01)\n",
        "epochs = 3000\n",
        "for epoch in range(epochs):\n",
        "    H = x_train * W + b\n",
        "    cost = torch.mean((H - y_train) ** 2)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    if (epoch+1) % 300 == 0:\n",
        "            print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n",
        "                    (epoch+1), epochs, W.item(), b.item(), cost.item()\n",
        "            ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZsBhuwNdQRX",
        "outputId": "70b76df6-1717-4383-94b9-11ef908c581b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  300/3000 W: 1.637, b: 2.551 Cost: 0.302633\n",
            "Epoch  600/3000 W: 1.310, b: 3.296 Cost: 0.071409\n",
            "Epoch  900/3000 W: 1.150, b: 3.658 Cost: 0.016850\n",
            "Epoch 1200/3000 W: 1.073, b: 3.834 Cost: 0.003976\n",
            "Epoch 1500/3000 W: 1.035, b: 3.919 Cost: 0.000938\n",
            "Epoch 1800/3000 W: 1.017, b: 3.961 Cost: 0.000221\n",
            "Epoch 2100/3000 W: 1.008, b: 3.981 Cost: 0.000052\n",
            "Epoch 2400/3000 W: 1.004, b: 3.991 Cost: 0.000012\n",
            "Epoch 2700/3000 W: 1.002, b: 3.996 Cost: 0.000003\n",
            "Epoch 3000/3000 W: 1.001, b: 3.998 Cost: 0.000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example: Linear Regression using nn.Module "
      ],
      "metadata": {
        "id": "2dnVh7SAeXzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[5], [6], [7]])\n",
        "\n",
        "model = nn.Linear(1, 1)\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "epochs = 3000\n",
        "for epoch in range(epochs):\n",
        "    prediction = model(x_train)\n",
        "\n",
        "    cost = F.mse_loss(prediction, y_train)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    W, b = list(model.parameters())[0], list(model.parameters())[1]\n",
        "    if (epoch + 1) % 300 == 0:\n",
        "        print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format((epoch + 1), epochs, W.item(), b.item(),\n",
        "                                                                        cost.item()))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zOH4_a8eYdq",
        "outputId": "55173e98-cb98-4faa-e599-c5ba3116e006"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  300/3000 W: 1.757, b: 2.279 Cost: 0.426866\n",
            "Epoch  600/3000 W: 1.368, b: 3.164 Cost: 0.100723\n",
            "Epoch  900/3000 W: 1.179, b: 3.594 Cost: 0.023767\n",
            "Epoch 1200/3000 W: 1.087, b: 3.803 Cost: 0.005608\n",
            "Epoch 1500/3000 W: 1.042, b: 3.904 Cost: 0.001323\n",
            "Epoch 1800/3000 W: 1.020, b: 3.953 Cost: 0.000312\n",
            "Epoch 2100/3000 W: 1.010, b: 3.977 Cost: 0.000074\n",
            "Epoch 2400/3000 W: 1.005, b: 3.989 Cost: 0.000017\n",
            "Epoch 2700/3000 W: 1.002, b: 3.995 Cost: 0.000004\n",
            "Epoch 3000/3000 W: 1.001, b: 3.997 Cost: 0.000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multivariable Regression  "
      ],
      "metadata": {
        "id": "sdKAQ_Ccfb3h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "x_train  =  torch.FloatTensor([[73,  80,  75],\n",
        "                               [93,  88,  93],\n",
        "                               [89,  91,  80],\n",
        "                               [96,  98,  100],\n",
        "                               [73,  66,  70]])\n",
        "y_train  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])\n",
        "\n",
        "W = torch.zeros((3, 1), requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "optimizer = optim.SGD([W, b], lr=1e-5)\n",
        "\n",
        "epochs = 10000\n",
        "for epoch in range(1, epochs+1):\n",
        "    hypothesis = x_train.matmul(W) + b\n",
        "\n",
        "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 1000 == 0:\n",
        "        print('Epoch {:4d}/{} hypothesis: {} Cost: {:.6f}'.format(\n",
        "                epoch, epochs, hypothesis.squeeze().detach(), cost.item()\n",
        "        ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYNU3NxTfcBR",
        "outputId": "ee986b60-2b52-4ce9-eb84-43121eab2e13"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1000/10000 hypothesis: tensor([153.8956, 184.8843, 176.6528, 198.1000, 141.2950]) Cost: 3.943436\n",
            "Epoch 2000/10000 hypothesis: tensor([153.7206, 184.7365, 177.3506, 197.6786, 141.4042]) Cost: 2.644381\n",
            "Epoch 3000/10000 hypothesis: tensor([153.5479, 184.6476, 177.8801, 197.3411, 141.5249]) Cost: 1.807667\n",
            "Epoch 4000/10000 hypothesis: tensor([153.3857, 184.5969, 178.2857, 197.0694, 141.6458]) Cost: 1.258096\n",
            "Epoch 5000/10000 hypothesis: tensor([153.2381, 184.5708, 178.5992, 196.8495, 141.7603]) Cost: 0.891718\n",
            "Epoch 6000/10000 hypothesis: tensor([153.1067, 184.5599, 178.8435, 196.6709, 141.8652]) Cost: 0.644825\n",
            "Epoch 7000/10000 hypothesis: tensor([152.9914, 184.5584, 179.0355, 196.5252, 141.9589]) Cost: 0.477134\n",
            "Epoch 8000/10000 hypothesis: tensor([152.8914, 184.5623, 179.1875, 196.4060, 142.0413]) Cost: 0.362609\n",
            "Epoch 9000/10000 hypothesis: tensor([152.8055, 184.5690, 179.3086, 196.3083, 142.1129]) Cost: 0.284092\n",
            "Epoch 10000/10000 hypothesis: tensor([152.7322, 184.5770, 179.4057, 196.2280, 142.1746]) Cost: 0.230119\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multivariable Regression using nn.Module "
      ],
      "metadata": {
        "id": "TbeLASzagmBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "x_train  =  torch.FloatTensor([[73,  80,  75],\n",
        "                               [93,  88,  93],\n",
        "                               [89,  91,  80],\n",
        "                               [96,  98,  100],\n",
        "                               [73,  66,  70]])\n",
        "\n",
        "y_train  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])\n",
        "\n",
        "model = nn.Linear(3,1)\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-5)\n",
        "\n",
        "epochs = 10000\n",
        "for epoch in range(1, epochs+1):\n",
        "    prediction = model(x_train)\n",
        "\n",
        "    cost = F.mse_loss(prediction, y_train)  \n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 1000 == 0:\n",
        "        print('Epoch {:4d}/{} hypothesis: {} Cost: {:.6f}'.format(\n",
        "                epoch, epochs, prediction.squeeze().detach(), cost.item()\n",
        "        ))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vh5pidPwgn14",
        "outputId": "96265720-3084-48ae-fbcc-397ceef9ef61"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1000/10000 hypothesis: tensor([152.4285, 185.6196, 176.9856, 197.2296, 142.7419]) Cost: 2.343208\n",
            "Epoch 2000/10000 hypothesis: tensor([152.5653, 185.2724, 177.7319, 196.9231, 142.5502]) Cost: 1.338537\n",
            "Epoch 3000/10000 hypothesis: tensor([152.6337, 185.0404, 178.2679, 196.6897, 142.4409]) Cost: 0.814669\n",
            "Epoch 4000/10000 hypothesis: tensor([152.6595, 184.8864, 178.6557, 196.5104, 142.3842]) Cost: 0.532613\n",
            "Epoch 5000/10000 hypothesis: tensor([152.6597, 184.7850, 178.9385, 196.3714, 142.3606]) Cost: 0.375238\n",
            "Epoch 6000/10000 hypothesis: tensor([152.6453, 184.7189, 179.1465, 196.2627, 142.3571]) Cost: 0.284090\n",
            "Epoch 7000/10000 hypothesis: tensor([152.6233, 184.6765, 179.3008, 196.1772, 142.3652]) Cost: 0.229360\n",
            "Epoch 8000/10000 hypothesis: tensor([152.5981, 184.6498, 179.4163, 196.1092, 142.3794]) Cost: 0.195405\n",
            "Epoch 9000/10000 hypothesis: tensor([152.5725, 184.6335, 179.5036, 196.0550, 142.3964]) Cost: 0.173734\n",
            "Epoch 10000/10000 hypothesis: tensor([152.5479, 184.6239, 179.5702, 196.0114, 142.4140]) Cost: 0.159593\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_1oda63shJJ9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}